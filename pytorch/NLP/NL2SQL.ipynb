{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('F:/workcode/NL2SQL/nl2sql_char_embedding_py3/char_embedding.json')\n",
    "word_emb = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/workcode/NL2SQL/nl2sql_train_20190618/train.json\n",
      "\n",
      "('F:/workcode/NL2SQL/nl2sql_train_20190618/train.json',)\n",
      "Loaded 41522 data from F:/workcode/NL2SQL/nl2sql_train_20190618/train.json\n",
      "Loaded 5013 data from F:/workcode/NL2SQL/nl2sql_train_20190618/train.tables.json\n"
     ]
    }
   ],
   "source": [
    "train_sql, train_table = load_data('F:/workcode/NL2SQL/nl2sql_train_20190618/train.json', 'F:/workcode/NL2SQL/nl2sql_train_20190618/train.tables.json', use_small=False)\n",
    "train_db = 'F:\\\\workcode\\\\NL2SQL\\\\nl2sql_train_20190618\\\\train.db'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sql=[]\n",
    "f=open('F:/workcode/NL2SQL/nl2sql_train_20190618/train.json',encoding='utf-8')\n",
    "line= f.readline()\n",
    "while line:\n",
    "    sql = json.loads(line.strip())\n",
    "    train_sql.append(sql)\n",
    "    line= f.readline()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = {}\n",
    "f=open('F:/workcode/NL2SQL/nl2sql_train_20190618/train.tables.json',encoding='utf-8')\n",
    "line= f.readline()\n",
    "while line:\n",
    "    tab = json.loads(line.strip())\n",
    "    table_data[tab[u'id']] = tab\n",
    "    line= f.readline()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from sqlnet.model.modules.word_embedding import WordEmbedding\n",
    "from sqlnet.model.modules.aggregator_predict import AggPredictor\n",
    "from sqlnet.model.modules.selection_predict import SelPredictor\n",
    "from sqlnet.model.modules.sqlnet_condition_predict import SQLNetCondPredictor\n",
    "from sqlnet.model.modules.select_number import SelNumPredictor\n",
    "from sqlnet.model.modules.where_relation import WhereRelationPredictor\n",
    "\n",
    "try:\n",
    "    unicode\n",
    "except NameError:  # Python 3\n",
    "    unicode = str\n",
    "\n",
    "\n",
    "class SQLNet(nn.Module):\n",
    "    def __init__(self, word_emb, N_word=300, N_h=100, N_depth=2,gpu=False, use_ca=True, trainable_emb=False):\n",
    "        super(SQLNet, self).__init__()\n",
    "        self.use_ca = use_ca\n",
    "        self.trainable_emb = trainable_emb\n",
    "\n",
    "        self.gpu = 1\n",
    "        self.N_h = 100\n",
    "        self.N_depth = 2\n",
    "\n",
    "        self.max_col_num = 45\n",
    "        self.max_tok_num = 200\n",
    "        self.SQL_TOK = ['<UNK>', '<END>', 'WHERE', 'AND', 'OR', '==', '>', '<', '!=', '<BEG>']\n",
    "        self.COND_OPS = ['>', '<', '==', '!=']\n",
    "\n",
    "        # Word embedding\n",
    "        self.embed_layer = WordEmbedding(word_emb, 300, 1, self.SQL_TOK, our_model=True, trainable=trainable_emb)\n",
    "\n",
    "        # Predict the number of selected columns\n",
    "        self.sel_num = SelNumPredictor(N_word, N_h, N_depth, use_ca=use_ca)\n",
    "\n",
    "        #Predict which columns are selected\n",
    "        self.sel_pred = SelPredictor(N_word, N_h, N_depth, self.max_tok_num, use_ca=use_ca)\n",
    "\n",
    "        #Predict aggregation functions of corresponding selected columns\n",
    "        self.agg_pred = AggPredictor(N_word, N_h, N_depth, use_ca=use_ca)\n",
    "\n",
    "        #Predict number of conditions, condition columns, condition operations and condition values\n",
    "        self.cond_pred = SQLNetCondPredictor(N_word, N_h, N_depth, self.max_col_num, self.max_tok_num, use_ca, gpu)\n",
    "\n",
    "        # Predict condition relationship, like 'and', 'or'\n",
    "        self.where_rela_pred = WhereRelationPredictor(N_word, N_h, N_depth, use_ca=use_ca)\n",
    "\n",
    "\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.log_softmax = nn.LogSoftmax()\n",
    "        self.bce_logit = nn.BCEWithLogitsLoss()\n",
    "        if gpu:\n",
    "            self.cuda()\n",
    "\n",
    "    def generate_gt_where_seq_test(self, q, gt_cond_seq):\n",
    "        ret_seq = []\n",
    "        for cur_q, ans in zip(q, gt_cond_seq):\n",
    "            temp_q = u\"\".join(cur_q)\n",
    "            cur_q = [u'<BEG>'] + cur_q + [u'<END>']\n",
    "            record = []\n",
    "            record_cond = []\n",
    "            for cond in ans:\n",
    "                if cond[2] not in temp_q:\n",
    "                    record.append((False, cond[2]))\n",
    "                else:\n",
    "                    record.append((True, cond[2]))\n",
    "            for idx, item in enumerate(record):\n",
    "                temp_ret_seq = []\n",
    "                if item[0]:\n",
    "                    temp_ret_seq.append(0)\n",
    "                    temp_ret_seq.extend(list(range(temp_q.index(item[1])+1,temp_q.index(item[1])+len(item[1])+1)))\n",
    "                    temp_ret_seq.append(len(cur_q)-1)\n",
    "                else:\n",
    "                    temp_ret_seq.append([0,len(cur_q)-1])\n",
    "                record_cond.append(temp_ret_seq)\n",
    "            ret_seq.append(record_cond)\n",
    "        return ret_seq\n",
    "\n",
    "    def forward(self, q, col, col_num, gt_where = None, gt_cond=None, reinforce=False, gt_sel=None, gt_sel_num=None):\n",
    "        B = len(q)\n",
    "\n",
    "        sel_num_score = None\n",
    "        agg_score = None\n",
    "        sel_score = None\n",
    "        cond_score = None\n",
    "        #Predict aggregator\n",
    "        if self.trainable_emb:\n",
    "            x_emb_var, x_len = self.agg_embed_layer.gen_x_batch(q, col)\n",
    "            col_inp_var, col_name_len, col_len = self.agg_embed_layer.gen_col_batch(col)\n",
    "            max_x_len = max(x_len)\n",
    "            agg_score = self.agg_pred(x_emb_var, x_len, col_inp_var,\n",
    "                    col_name_len, col_len, col_num, gt_sel=gt_sel)\n",
    "\n",
    "            x_emb_var, x_len = self.sel_embed_layer.gen_x_batch(q, col)\n",
    "            col_inp_var, col_name_len, col_len = self.sel_embed_layer.gen_col_batch(col)\n",
    "            max_x_len = max(x_len)\n",
    "            sel_score = self.sel_pred(x_emb_var, x_len, col_inp_var,\n",
    "                    col_name_len, col_len, col_num)\n",
    "\n",
    "            x_emb_var, x_len = self.cond_embed_layer.gen_x_batch(q, col)\n",
    "            col_inp_var, col_name_len, col_len = self.cond_embed_layer.gen_col_batch(col)\n",
    "            max_x_len = max(x_len)\n",
    "            cond_score = self.cond_pred(x_emb_var, x_len, col_inp_var, col_name_len, col_len, col_num, gt_where, gt_cond, reinforce=reinforce)\n",
    "            where_rela_score = None\n",
    "        else:\n",
    "            x_emb_var, x_len = self.embed_layer.gen_x_batch(q, col)\n",
    "            col_inp_var, col_name_len, col_len = self.embed_layer.gen_col_batch(col)\n",
    "            sel_num_score = self.sel_num(x_emb_var, x_len, col_inp_var, col_name_len, col_len, col_num)\n",
    "            # x_emb_var: embedding of each question\n",
    "            # x_len: length of each question\n",
    "            # col_inp_var: embedding of each header\n",
    "            # col_name_len: length of each header\n",
    "            # col_len: number of headers in each table, array type\n",
    "            # col_num: number of headers in each table, list type\n",
    "            if gt_sel_num:\n",
    "                pr_sel_num = gt_sel_num\n",
    "            else:\n",
    "                pr_sel_num = np.argmax(sel_num_score.data.cpu().numpy(), axis=1)\n",
    "            sel_score = self.sel_pred(x_emb_var, x_len, col_inp_var, col_name_len, col_len, col_num)\n",
    "\n",
    "            if gt_sel:\n",
    "                pr_sel = gt_sel\n",
    "            else:\n",
    "                num = np.argmax(sel_num_score.data.cpu().numpy(), axis=1)\n",
    "                sel = sel_score.data.cpu().numpy()\n",
    "                pr_sel = [list(np.argsort(-sel[b])[:num[b]]) for b in range(len(num))]\n",
    "            agg_score = self.agg_pred(x_emb_var, x_len, col_inp_var, col_name_len, col_len, col_num, gt_sel=pr_sel, gt_sel_num=pr_sel_num)\n",
    "\n",
    "            where_rela_score = self.where_rela_pred(x_emb_var, x_len, col_inp_var, col_name_len, col_len, col_num)\n",
    "\n",
    "            cond_score = self.cond_pred(x_emb_var, x_len, col_inp_var, col_name_len, col_len, col_num, gt_where, gt_cond, reinforce=reinforce)\n",
    "\n",
    "        return (sel_num_score, sel_score, agg_score, cond_score, where_rela_score)\n",
    "\n",
    "    def loss(self, score, truth_num, gt_where):\n",
    "        sel_num_score, sel_score, agg_score, cond_score, where_rela_score = score\n",
    "\n",
    "        B = len(truth_num)\n",
    "        loss = 0\n",
    "\n",
    "        # Evaluate select number\n",
    "        # sel_num_truth = map(lambda x:x[0], truth_num)\n",
    "        sel_num_truth = [x[0] for x in truth_num]\n",
    "        sel_num_truth = torch.from_numpy(np.array(sel_num_truth))\n",
    "        if self.gpu:\n",
    "            sel_num_truth = sel_num_truth.long().cuda()\n",
    "        else:\n",
    "            sel_num_truth = sel_num_truth.long()\n",
    "        loss += self.CE(sel_num_score, sel_num_truth)\n",
    "\n",
    "        # Evaluate select column\n",
    "        T = len(sel_score[0])\n",
    "        truth_prob = np.zeros((B,T), dtype=np.float32)\n",
    "        for b in range(B):\n",
    "            truth_prob[b][list(truth_num[b][1])] = 1\n",
    "        data = torch.from_numpy(truth_prob)\n",
    "        if self.gpu:\n",
    "            sel_col_truth_var = Variable(data.cuda())\n",
    "        else:\n",
    "            sel_col_truth_var = Variable(data)\n",
    "        sigm = nn.Sigmoid()\n",
    "        sel_col_prob = sigm(sel_score)\n",
    "        bce_loss = -torch.mean(\n",
    "            3*(sel_col_truth_var * torch.log(sel_col_prob+1e-10)) +\n",
    "            (1-sel_col_truth_var) * torch.log(1-sel_col_prob+1e-10)\n",
    "        )\n",
    "        loss += bce_loss\n",
    "\n",
    "        # Evaluate select aggregation\n",
    "        for b in range(len(truth_num)):\n",
    "            data = torch.from_numpy(np.array(truth_num[b][2]))\n",
    "            if self.gpu:\n",
    "                sel_agg_truth_var = data.long().cuda()\n",
    "            else:\n",
    "                sel_agg_truth_var = data.long()\n",
    "            sel_agg_pred = agg_score[b, :len(truth_num[b][1])]\n",
    "            loss += (self.CE(sel_agg_pred, sel_agg_truth_var)) / len(truth_num)\n",
    "\n",
    "        cond_num_score, cond_col_score, cond_op_score, cond_str_score = cond_score\n",
    "\n",
    "        # Evaluate the number of conditions\n",
    "        # cond_num_truth = map(lambda x:x[3], truth_num)\n",
    "        cond_num_truth = [x[3] for x in truth_num]\n",
    "        data = torch.from_numpy(np.array(cond_num_truth))\n",
    "        if self.gpu:\n",
    "            try:\n",
    "                cond_num_truth_var = data.long().cuda()\n",
    "            except:\n",
    "                print (\"cond_num_truth_var error\")\n",
    "                print (data)\n",
    "                exit(0)\n",
    "        else:\n",
    "            cond_num_truth_var = data.long()\n",
    "        loss += self.CE(cond_num_score, cond_num_truth_var)\n",
    "\n",
    "        # Evaluate the columns of conditions\n",
    "        T = len(cond_col_score[0])\n",
    "        truth_prob = np.zeros((B, T), dtype=np.float32)\n",
    "        for b in range(B):\n",
    "            if len(truth_num[b][4]) > 0:\n",
    "                truth_prob[b][list(truth_num[b][4])] = 1\n",
    "        data = torch.from_numpy(truth_prob)\n",
    "        if self.gpu:\n",
    "            cond_col_truth_var = Variable(data.cuda())\n",
    "        else:\n",
    "            cond_col_truth_var = Variable(data)\n",
    "\n",
    "        sigm = nn.Sigmoid()\n",
    "        cond_col_prob = sigm(cond_col_score)\n",
    "        bce_loss = -torch.mean(\n",
    "            3*(cond_col_truth_var * torch.log(cond_col_prob+1e-10)) +\n",
    "            (1-cond_col_truth_var) * torch.log(1-cond_col_prob+1e-10) )\n",
    "        loss += bce_loss\n",
    "\n",
    "        # Evaluate the operator of conditions\n",
    "        for b in range(len(truth_num)):\n",
    "            if len(truth_num[b][5]) == 0:\n",
    "                continue\n",
    "            data = torch.from_numpy(np.array(truth_num[b][5]))\n",
    "            if self.gpu:\n",
    "                cond_op_truth_var = data.long().cuda()\n",
    "            else:\n",
    "                cond_op_truth_var = data.long()\n",
    "            cond_op_pred = cond_op_score[b, :len(truth_num[b][5])]\n",
    "            try:\n",
    "                loss += (self.CE(cond_op_pred, cond_op_truth_var) / len(truth_num))\n",
    "            except:\n",
    "                print('some except')\n",
    "                print (cond_op_pred)\n",
    "                print (cond_op_truth_var)\n",
    "                exit(0)\n",
    "\n",
    "        #Evaluate the strings of conditions\n",
    "        for b in range(len(gt_where)):\n",
    "            for idx in range(len(gt_where[b])):\n",
    "                cond_str_truth = gt_where[b][idx]\n",
    "                if len(cond_str_truth) == 1:\n",
    "                    continue\n",
    "                data = torch.from_numpy(np.array(cond_str_truth[1:]))\n",
    "                if self.gpu:\n",
    "                    cond_str_truth_var = data.long().cuda()\n",
    "                else:\n",
    "                    cond_str_truth_var = data.long()\n",
    "                str_end = len(cond_str_truth)-1\n",
    "                cond_str_pred = cond_str_score[b, idx, :str_end]\n",
    "                loss += (self.CE(cond_str_pred, cond_str_truth_var) \\\n",
    "                        / (len(gt_where) * len(gt_where[b])))\n",
    "\n",
    "        # Evaluate condition relationship, and / or\n",
    "        # where_rela_truth = map(lambda x:x[6], truth_num)\n",
    "        where_rela_truth = [x[6] for x in truth_num]\n",
    "        data = torch.from_numpy(np.array(where_rela_truth))\n",
    "        if self.gpu:\n",
    "            try:\n",
    "                where_rela_truth = data.long().cuda()\n",
    "            except:\n",
    "                print (\"where_rela_truth error\")\n",
    "                print (data)\n",
    "                exit(0)\n",
    "        else:\n",
    "            where_rela_truth = data.long()\n",
    "        loss += self.CE(where_rela_score, where_rela_truth)\n",
    "        return loss\n",
    "\n",
    "    def check_acc(self, vis_info, pred_queries, gt_queries):\n",
    "        def gen_cond_str(conds, header):\n",
    "            if len(conds) == 0:\n",
    "                return 'None'\n",
    "            cond_str = []\n",
    "            for cond in conds:\n",
    "                cond_str.append(header[cond[0]] + ' ' +\n",
    "                    self.COND_OPS[cond[1]] + ' ' + unicode(cond[2]).lower())\n",
    "            return 'WHERE ' + ' AND '.join(cond_str)\n",
    "\n",
    "        tot_err = sel_num_err = agg_err = sel_err = 0.0\n",
    "        cond_num_err = cond_col_err = cond_op_err = cond_val_err = cond_rela_err = 0.0\n",
    "        for b, (pred_qry, gt_qry) in enumerate(zip(pred_queries, gt_queries)):\n",
    "            good = True\n",
    "            sel_pred, agg_pred, where_rela_pred = pred_qry['sel'], pred_qry['agg'], pred_qry['cond_conn_op']\n",
    "            sel_gt, agg_gt, where_rela_gt = gt_qry['sel'], gt_qry['agg'], gt_qry['cond_conn_op']\n",
    "\n",
    "            if where_rela_gt != where_rela_pred:\n",
    "                good = False\n",
    "                cond_rela_err += 1\n",
    "\n",
    "            if len(sel_pred) != len(sel_gt):\n",
    "                good = False\n",
    "                sel_num_err += 1\n",
    "\n",
    "            pred_sel_dict = {k:v for k,v in zip(list(sel_pred), list(agg_pred))}\n",
    "            gt_sel_dict = {k:v for k,v in zip(sel_gt, agg_gt)}\n",
    "            if set(sel_pred) != set(sel_gt):\n",
    "                good = False\n",
    "                sel_err += 1\n",
    "            agg_pred = [pred_sel_dict[x] for x in sorted(pred_sel_dict.keys())]\n",
    "            agg_gt = [gt_sel_dict[x] for x in sorted(gt_sel_dict.keys())]\n",
    "            if agg_pred != agg_gt:\n",
    "                good = False\n",
    "                agg_err += 1\n",
    "\n",
    "            cond_pred = pred_qry['conds']\n",
    "            cond_gt = gt_qry['conds']\n",
    "            if len(cond_pred) != len(cond_gt):\n",
    "                good = False\n",
    "                cond_num_err += 1\n",
    "            else:\n",
    "                cond_op_pred, cond_op_gt = {}, {}\n",
    "                cond_val_pred, cond_val_gt = {}, {}\n",
    "                for p, g in zip(cond_pred, cond_gt):\n",
    "                    cond_op_pred[p[0]] = p[1]\n",
    "                    cond_val_pred[p[0]] = p[2]\n",
    "                    cond_op_gt[g[0]] = g[1]\n",
    "                    cond_val_gt[g[0]] = g[2]\n",
    "\n",
    "                if set(cond_op_pred.keys()) != set(cond_op_gt.keys()):\n",
    "                    cond_col_err += 1\n",
    "                    good=False\n",
    "\n",
    "                where_op_pred = [cond_op_pred[x] for x in sorted(cond_op_pred.keys())]\n",
    "                where_op_gt = [cond_op_gt[x] for x in sorted(cond_op_gt.keys())]\n",
    "                if where_op_pred != where_op_gt:\n",
    "                    cond_op_err += 1\n",
    "                    good=False\n",
    "\n",
    "                where_val_pred = [cond_val_pred[x] for x in sorted(cond_val_pred.keys())]\n",
    "                where_val_gt = [cond_val_gt[x] for x in sorted(cond_val_gt.keys())]\n",
    "                if where_val_pred != where_val_gt:\n",
    "                    cond_val_err += 1\n",
    "                    good=False\n",
    "\n",
    "            if not good:\n",
    "                tot_err += 1\n",
    "\n",
    "        return np.array((sel_num_err, sel_err, agg_err, cond_num_err, cond_col_err, cond_op_err, cond_val_err , cond_rela_err)), tot_err\n",
    "\n",
    "\n",
    "    def gen_query(self, score, q, col, raw_q, reinforce=False, verbose=False):\n",
    "        \"\"\"\n",
    "        :param score:\n",
    "        :param q: token-questions\n",
    "        :param col: token-headers\n",
    "        :param raw_q: original question sequence\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        def merge_tokens(tok_list, raw_tok_str):\n",
    "            tok_str = raw_tok_str# .lower()\n",
    "            alphabet = 'abcdefghijklmnopqrstuvwxyz0123456789$('\n",
    "            special = {'-LRB-':'(',\n",
    "                    '-RRB-':')',\n",
    "                    '-LSB-':'[',\n",
    "                    '-RSB-':']',\n",
    "                    '``':'\"',\n",
    "                    '\\'\\'':'\"',\n",
    "                    '--':u'\\u2013'}\n",
    "            ret = ''\n",
    "            double_quote_appear = 0\n",
    "            for raw_tok in tok_list:\n",
    "                if not raw_tok:\n",
    "                    continue\n",
    "                tok = special.get(raw_tok, raw_tok)\n",
    "                if tok == '\"':\n",
    "                    double_quote_appear = 1 - double_quote_appear\n",
    "                if len(ret) == 0:\n",
    "                    pass\n",
    "                elif len(ret) > 0 and ret + ' ' + tok in tok_str:\n",
    "                    ret = ret + ' '\n",
    "                elif len(ret) > 0 and ret + tok in tok_str:\n",
    "                    pass\n",
    "                elif tok == '\"':\n",
    "                    if double_quote_appear:\n",
    "                        ret = ret + ' '\n",
    "                # elif tok[0] not in alphabet:\n",
    "                #     pass\n",
    "                elif (ret[-1] not in ['(', '/', u'\\u2013', '#', '$', '&']) \\\n",
    "                        and (ret[-1] != '\"' or not double_quote_appear):\n",
    "                    ret = ret + ' '\n",
    "                ret = ret + tok\n",
    "            return ret.strip()\n",
    "\n",
    "        sel_num_score, sel_score, agg_score, cond_score, where_rela_score = score\n",
    "        # [64,4,6], [64,14], ..., [64,4]\n",
    "        sel_num_score = sel_num_score.data.cpu().numpy()\n",
    "        sel_score = sel_score.data.cpu().numpy()\n",
    "        agg_score = agg_score.data.cpu().numpy()\n",
    "        where_rela_score = where_rela_score.data.cpu().numpy()\n",
    "        ret_queries = []\n",
    "        B = len(agg_score)\n",
    "        cond_num_score,cond_col_score,cond_op_score,cond_str_score =\\\n",
    "            [x.data.cpu().numpy() for x in cond_score]\n",
    "        for b in range(B):\n",
    "            cur_query = {}\n",
    "            cur_query['sel'] = []\n",
    "            cur_query['agg'] = []\n",
    "            sel_num = np.argmax(sel_num_score[b])\n",
    "            max_col_idxes = np.argsort(-sel_score[b])[:sel_num]\n",
    "            # find the most-probable columns' indexes\n",
    "            max_agg_idxes = np.argsort(-agg_score[b])[:sel_num]\n",
    "            cur_query['sel'].extend([int(i) for i in max_col_idxes])\n",
    "            cur_query['agg'].extend([i[0] for i in max_agg_idxes])\n",
    "            cur_query['cond_conn_op'] = np.argmax(where_rela_score[b])\n",
    "            cur_query['conds'] = []\n",
    "            cond_num = np.argmax(cond_num_score[b])\n",
    "            all_toks = ['<BEG>'] + q[b] + ['<END>']\n",
    "            max_idxes = np.argsort(-cond_col_score[b])[:cond_num]\n",
    "            for idx in range(cond_num):\n",
    "                cur_cond = []\n",
    "                cur_cond.append(max_idxes[idx]) # where-col\n",
    "                cur_cond.append(np.argmax(cond_op_score[b][idx])) # where-op\n",
    "                cur_cond_str_toks = []\n",
    "                for str_score in cond_str_score[b][idx]:\n",
    "                    str_tok = np.argmax(str_score[:len(all_toks)])\n",
    "                    str_val = all_toks[str_tok]\n",
    "                    if str_val == '<END>':\n",
    "                        break\n",
    "                    cur_cond_str_toks.append(str_val)\n",
    "                cur_cond.append(merge_tokens(cur_cond_str_toks, raw_q[b]))\n",
    "                cur_query['conds'].append(cur_cond)\n",
    "            ret_queries.append(cur_query)\n",
    "        return ret_queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = 'F:\\\\workcode\\\\NL2SQL\\\\nl2sql_train_20190618\\\\train.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SQLNet(word_emb, N_word=300, use_ca=ture, gpu=1, trainable_emb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
